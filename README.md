
# Containerization of Data Science Workflows for CI/CD  
### Telecom Customer Churn Prediction (MLOps Project)

## ğŸ“Œ Project Overview
This project demonstrates how **Data Science workflows can be containerized and automated using CI/CD pipelines**.  
It focuses on predicting **customer churn in the telecom industry** using machine learning, while showcasing **DevOps + MLOps practices** such as Docker, GitHub Actions, and modular pipelines.

The system includes:
- A complete ML pipeline (data preprocessing â†’ training â†’ evaluation)
- A Streamlit-based interactive dashboard (frontend)
- A FastAPI backend for model inference
- Docker-based containerization
- Automated CI/CD using GitHub Actions

---

## ğŸ¯ Problem Statement
Customer churn refers to customers leaving a service provider.  
In the telecom industry, churn rates can reach **15â€“25% annually**, making early prediction critical.

This project predicts churn in advance so that companies can:
- Identify high-risk customers
- Take preventive retention actions
- Reduce customer loss and revenue impact

---

## ğŸ“Š Dataset
**Telco Customer Churn Dataset**

Contains:
- Customer demographics (gender, senior citizen, dependents)
- Account information (tenure, contract, billing)
- Services used (internet, security, tech support)
- Target variable: `Churn`

---

## ğŸ”„ Data Science Workflow
1. **Data Ingestion**
2. **Data Preprocessing**
   - Handling missing values
   - Encoding categorical variables
   - Feature scaling
3. **Model Training**
   - Logistic Regression
   - Random Forest
   - Gradient Boosting
   - XGBoost
   - (Optional) LightGBM, CatBoost
4. **Model Evaluation**
   - Accuracy
   - Precision
   - Recall
   - F1-score
   - ROC Curve & Confusion Matrix
5. **Model Selection**
   - Best model selected automatically
6. **Model Deployment**
   - Served via backend API
   - Visualized using Streamlit

---

## ğŸ§  Machine Learning Models
- Logistic Regression  
- Random Forest  
- Gradient Boosting  
- XGBoost  
- Voting / Best Model Selection  

The **best-performing model** is automatically saved and used for predictions.

---

## ğŸ–¥ï¸ Frontend (Streamlit Dashboard)
- KPI metrics (Churn rate, High-risk customers)
- Segment analysis (Contract, Internet, Payment Method)
- Feature importance visualization
- Top at-risk customers table
- Individual customer churn prediction
- Retention recommendations for high-risk customers

---

## âš™ï¸ Backend (FastAPI)
- REST API for churn prediction
- Separates model logic from UI
- Enables scalable deployment
- Used by Streamlit for predictions

---

## ğŸ³ Containerization (Docker)
- Frontend and backend run in separate containers
- Ensures environment consistency
- Easily deployable on any system

Run everything with:
```bash
docker compose up --build
````

---

## ğŸ” CI/CD Pipeline (GitHub Actions)

On every push:

1. Run data preprocessing
2. Train ML models
3. Evaluate model performance
4. Save model and metrics as artifacts
5. Build Docker image

This ensures **continuous integration and automation of ML workflows**.

---

## ğŸ—ï¸ Project Structure

```
churn-mlops-ci-cd/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original dataset (telco_churn.csv)
â”‚ â””â”€â”€ processed/ # Preprocessed dataset (auto-generated)
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_preprocessing.py # Data cleaning & feature engineering
â”‚ â”œâ”€â”€ train_model.py # Model training & selection
â”‚ â””â”€â”€ evaluate.py # Model evaluation
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ model.pkl # Best trained ML model
â”‚ â”œâ”€â”€ scaler.pkl
â”‚ â”œâ”€â”€ label_encoders.pkl
â”‚ â”œâ”€â”€ columns.pkl
â”‚ â””â”€â”€ metrics.json # Evaluation summary
â”‚
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ cm_.png # Confusion matrices
â”‚ â””â”€â”€ roc_.png # ROC curves
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ api.py # FastAPI backend
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ app.py # Streamlit frontend
â”‚ â””â”€â”€ Dockerfile # Frontend Dockerfile
â”‚
â”œâ”€â”€ pipeline/
â”‚ â””â”€â”€ Dockerfile # ML pipeline container
â”‚
â”œâ”€â”€ docker-compose.yml # Orchestrates frontend + backend
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ ci-cd.yaml # CI/CD workflow
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run Locally

### Option 1: Docker (Recommended)

```bash
docker compose up --build
```

Frontend: [http://localhost:8501](http://localhost:8501)
Backend: [http://localhost:8000](http://localhost:8000)

---

### Option 2: Without Docker

```bash
python src/data_preprocessing.py
python src/train_model.py
python src/evaluate.py
streamlit run app/app.py
```

---

## âœ… Key Outcomes

* Automated ML pipeline
* Containerized deployment
* CI/CD-enabled model training
* Business-focused churn insights
* Clean MLOps architecture

---

## ğŸ”® Future Enhancements

* Add database for prediction history
* Advanced hyperparameter tuning
* Cloud deployment (AWS / GCP)
* Role-based dashboards
* Real-time streaming data

---

## ğŸ“Œ Technologies Used

* Python
* Scikit-learn
* Streamlit
* FastAPI
* Docker & Docker Compose
* GitHub Actions
* Pandas, NumPy, Matplotlib, Plotly

---

## ğŸ‘¤ Author

**Anjani Nandyala**
Third Year B.Tech (CSE)
