
# ðŸ“Š Telco Customer Churn Prediction â€“ MLOps Project

## 1. Project Overview
This project demonstrates **Containerization of Data Science Workflows for CI/CD** using Docker, Streamlit, and GitHub Actions.  
The workflow automates:

- Data preprocessing  
- Model training  
- Model evaluation  
- Frontend deployment with Streamlit  

It showcases **MLOps principles**, ensuring your ML pipeline runs consistently on any system.

---

## 2. Features
- Load and preprocess Telco customer dataset  
- Train a Logistic Regression model for churn prediction  
- Evaluate model performance (Accuracy, Precision, Recall, F1 Score)  
- Streamlit frontend for live predictions and metrics  
- Containerized using Docker (pipeline + frontend)  
- CI/CD with GitHub Actions

---

## 3. Project Structure

```

churn-prediction-project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original dataset (telco_churn.csv)
â”‚   â””â”€â”€ processed/           # Processed dataset (generated automatically)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl             # Saved ML model
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                # Streamlit frontend
â”‚   â””â”€â”€ Dockerfile            # Docker container for frontend
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ Dockerfile            # Pipeline container
â”‚   â””â”€â”€ entrypoint.sh         # Script to run preprocessing, training, evaluation
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yaml            # GitHub Actions workflow for CI/CD
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb             # Exploratory Data Analysis
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## 4. Setup & Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd churn-prediction-project
````

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Create data folders**

```bash
mkdir -p data/raw
mkdir -p data/processed
```

4. **Place dataset**
   Place `telco_churn.csv` inside `data/raw/`.

---

## 5. Run Locally (Python)

1. **Preprocess data**

```bash
python src/data_preprocessing.py
```

2. **Train model**

```bash
python src/train_model.py
```

3. **Evaluate model**

```bash
python src/evaluate.py
```

4. **Run Streamlit frontend**

```bash
streamlit run app/app.py
```

Open browser at: `http://localhost:8501`

---

## 6. Run with Docker

### ðŸŸ¢ Pipeline Container

```bash
docker build -t churn-pipeline ./pipeline
docker run --rm churn-pipeline
```

### ðŸŸ¢ Streamlit Frontend Container

```bash
docker build -t churn-streamlit ./app
docker run -p 8501:8501 churn-streamlit
```

---

## 7. CI/CD (GitHub Actions)

* Triggers on push or pull request to `main` branch
* Steps:

  1. Install dependencies
  2. Run preprocessing, training, evaluation
  3. Save model and metrics as artifacts
  4. Build Streamlit Docker image

---

## 8. Folder Contents

* `data/raw` â†’ Original CSV
* `data/processed` â†’ Preprocessed CSV
* `models` â†’ Saved model and metrics
* `src` â†’ ML pipeline scripts
* `app` â†’ Streamlit UI + Dockerfile
* `pipeline` â†’ Docker pipeline + entrypoint script
* `.github/workflows` â†’ CI/CD YAML
* `notebooks` â†’ EDA
* `requirements.txt` â†’ Dependencies

---

## 9. References

* [Telco Customer Churn Dataset - Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
* Scikit-learn Documentation: [https://scikit-learn.org](https://scikit-learn.org)
* Streamlit Documentation: [https://docs.streamlit.io](https://docs.streamlit.io)
* Docker Documentation: [https://docs.docker.com](https://docs.docker.com)
* GitHub Actions: [https://docs.github.com/en/actions](https://docs.github.com/en/actions)

---

## 10. Authors

**Anjani Nandyala**
B.Tech CSE â€“ Final Year
Project: Containerization of Data Science Workflows for CI/CD

```

---

If you want, I can **next create a ready-to-use project architecture diagram (`architecture_diagram.png`)** that matches this README and is perfect for your viva/demo.  

Do you want me to do that next?
```
