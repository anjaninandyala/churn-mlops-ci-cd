


# Containerization of Data Science Workflows for CI/CD  
## Telecom Customer Churn Prediction (MLOps Project)



## ğŸ“Œ Project Overview
This project demonstrates how **data science workflows can be containerized and automated using CI/CD pipelines**.  
It focuses on predicting **customer churn in the telecom industry** using machine learning, while showcasing **DevOps and MLOps practices** such as Docker, GitHub Actions, and modular pipelines.

The system includes:
- A complete ML pipeline (data preprocessing â†’ training â†’ evaluation)
- A Streamlit-based interactive dashboard (frontend)
- A FastAPI backend for model inference
- Docker-based containerization
- Automated CI/CD using GitHub Actions

This project ensures **reproducibility, scalability, and automation** of machine learning workflows.

---

## ğŸ¯ Problem Statement
Customer churn refers to customers discontinuing a service.  
In the telecom industry, churn rates can reach **15â€“25% annually**, making early prediction critical.

By predicting churn in advance, telecom companies can:
- Identify high-risk customers
- Apply targeted retention strategies
- Reduce customer loss and revenue impact

---

## ğŸ“Š Dataset
**Telco Customer Churn Dataset**

The dataset contains:
- Customer demographics (gender, senior citizen, dependents)
- Account information (tenure, contract type, billing method)
- Services used (internet, security, tech support, streaming)
- Target variable: `Churn`

---

## ğŸ”„ Data Science Workflow
1. **Data Ingestion**
2. **Data Preprocessing**
   - Handling missing values
   - Encoding categorical variables
   - Feature scaling
3. **Model Training**
   - Logistic Regression
   - Random Forest
   - Gradient Boosting
   - XGBoost
   - (Optional) LightGBM, CatBoost
4. **Model Evaluation**
   - Accuracy
   - Precision
   - Recall
   - F1-score
   - ROC Curve and Confusion Matrix
5. **Model Selection**
   - Best-performing model selected automatically
6. **Model Deployment**
   - Served through a FastAPI backend
   - Visualized using Streamlit frontend

---

## ğŸ§  Machine Learning Models
- Logistic Regression  
- Random Forest  
- Gradient Boosting  
- XGBoost  
- Voting / Best Model Selection  

The **best-performing model** is automatically saved and used for predictions.

---

## ğŸ–¥ï¸ Frontend (Streamlit Dashboard)
The Streamlit dashboard provides:
- KPI metrics (churn rate, high-risk customers)
- Segment analysis (contract type, internet service, payment method)
- Feature importance visualization
- Top at-risk customers table
- Individual customer churn prediction
- Retention recommendations for high-risk customers

---

## âš™ï¸ Backend (FastAPI)
- Provides REST APIs for churn prediction
- Separates model inference logic from the UI
- Enables modular and scalable architecture
- Streamlit frontend communicates with backend via HTTP requests

---

## ğŸ³ Containerization (Docker)
- Frontend and backend run in separate containers
- Ensures environment consistency across systems
- Simplifies deployment and scaling

Run the entire system using:
```bash
docker compose up --build
````

---

## ğŸ” CI/CD Pipeline (GitHub Actions)

On every push to the main branch, the pipeline automatically:

1. Runs data preprocessing
2. Trains machine learning models
3. Evaluates model performance
4. Saves model and metrics as artifacts
5. Builds Docker images

This ensures **continuous integration and automation of ML workflows**.

---

## ğŸ—ï¸ Project Structure

```
churn-mlops-ci-cd/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original dataset (telco_churn.csv)
â”‚   â””â”€â”€ processed/            # Preprocessed dataset (auto-generated)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py # Data cleaning & feature engineering
â”‚   â”œâ”€â”€ train_model.py        # Model training & selection
â”‚   â””â”€â”€ evaluate.py           # Model evaluation
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl             # Best trained ML model
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ label_encoders.pkl
â”‚   â”œâ”€â”€ columns.pkl
â”‚   â””â”€â”€ metrics.json          # Evaluation summary
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ cm_*.png              # Confusion matrices
â”‚   â””â”€â”€ roc_*.png             # ROC curves
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py                # FastAPI backend
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                # Streamlit frontend
â”‚   â””â”€â”€ Dockerfile            # Frontend Dockerfile
â”‚
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ Dockerfile            # ML pipeline container
â”‚
â”œâ”€â”€ docker-compose.yml        # Orchestrates frontend + backend
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yaml             # CI/CD workflow
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run Locally

### Option 1: Docker (Recommended)

```bash
docker compose up --build
```

* Frontend: [http://localhost:8501](http://localhost:8501)
* Backend: [http://localhost:8000](http://localhost:8000)

---

### Option 2: Without Docker

```bash
python src/data_preprocessing.py
python src/train_model.py
python src/evaluate.py
streamlit run app/app.py
```

---

## âœ… Key Outcomes

* End-to-end automated ML pipeline
* Containerized frontend and backend
* CI/CD-enabled model training and evaluation
* Business-focused churn insights
* Clean and scalable MLOps architecture

---

## ğŸ”® Future Enhancements

* Database integration for prediction history
* Advanced hyperparameter tuning
* Cloud deployment (AWS / GCP)
* Role-based dashboards
* Real-time streaming data integration

---

## ğŸ“Œ Technologies Used

* Python
* Scikit-learn
* Streamlit
* FastAPI
* Docker & Docker Compose
* GitHub Actions
* Pandas, NumPy, Matplotlib, Plotly

---

## ğŸ‘¤ Author

**Anjani Nandyala**
B.Tech â€“ Computer Science & Engineering
Final Year Project
**Title:** Containerization of Data Science Workflows for CI/CD

